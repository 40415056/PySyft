{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Neural Network (SplitNN)\n",
    "\n",
    "Traditionally, PySyft has been used to facilitate federated learning. However, we can also leverage the tools included in this framework to implement distributed neural networks. \n",
    "\n",
    "### What is a SplitNN?\n",
    "\n",
    "<img src=\"images/anatomy.png\" width=\"50%\">\n",
    "\n",
    "The training of a neural network (NN) is 'split' accross a chain of multiple hosts. Each segment in the chain is a self contained NN that feeds into the segment in front. The host with the training data has the beginning segment of the network and the end segment. Intermediate segments of the chain are held by participating hosts.\n",
    "\n",
    "### Training Process\n",
    "\n",
    "The SplitNN network is assembled as a chain of NNs, each feeding into the next. The data subject has both the beginning and the end of this chain.\n",
    "\n",
    "<img src=\"images/training.png\" width=\"80%\">\n",
    "\n",
    "When forward propogation commences, the data subject propogates the x values forward through the network at the start of the chain and sends their activation signals to the next intermediate host. This host feeds the recieved activation signal forward through their network and to the next link in the chain. This continues until the end of the chain is reached. The data subject then recieves an activation signal and forward propogates. They then compute the loss using their y-values.\n",
    "\n",
    "They backward propogate the gradients of the activation signals they recieved to the host previous to them in the chain. This host then computes their gradients, sending the gradient of the activeation signal backward. Eventually, the data subject recieves the gradients of their activation signal at the start of the chain and computes gradients. \n",
    "\n",
    "The NNs in the chain update their weights and biases, commenceing the next epoch. When a host is finished training, they pass the front and end segments to the next person with data to train.\n",
    "\n",
    "<img src=\"images/BatchFlow.png\" width=\"40%\">\n",
    "\n",
    "\n",
    "### Why use a SplitNN?\n",
    "\n",
    "The SplitNN has been shown to provide a dramatic reduction to the computational burden of training while maintaining higher accuracies when training over large number of clients [[1](https://arxiv.org/abs/1812.00564)]. In the figure below, the Blue line denotes distributed deep learning using splitNN, red line indicate federated learning (FL) and green line indicates Large Batch Stochastic Gradient Descent (LBSGD).\n",
    "\n",
    "<img src=\"images/AccuracyvsFlops.png\" width=\"60%\">\n",
    "\n",
    "<img src=\"images/computation.png\" width=\"40%\">\n",
    " \n",
    "Table 1 shows computational resources consumed when training CIFAR 10 over VGG. Theses are a fraction of the resources of FL and LBSGD. Table 2 shows the bandwith usage when training CIFAR 100 over ResNet. Federated learning is less bandwidth intensive with fewer than 100 clients. However, the SplitNN outperforms other approaches as the number of clients grow[[1](https://arxiv.org/abs/1812.00564)].\n",
    "\n",
    "<img src=\"images/bandwidth.png\" width=\"40%\">\n",
    "\n",
    "Using this technique, nobody knows the input data and labels apart from the data subject. All that is sent or recieved between nodes is activation signals during forward propogation and their corresponding gradients during backpropogation. Entropy can be added to the activation signals through adding layers to the model segments. Entropy of training data could potentially be measured to arrive at the appropriate number of layers to use in order to adequately hide the orignal values in start and end segments.\n",
    "\n",
    "During this process, no hosts involved in the learning process have a full picture of the network. As a result there is very little risk of the model being stolen by participating hosts. Models could only be fully recovered by malicious participants if they were to collude with every other host. \n",
    "\n",
    "### Advantages\n",
    "\n",
    "- The accuracy should be almost identical to a non-split version of the same model, trained locally. \n",
    "- Models and data can be homomorphically encrypted for added security at the cost of added computation.\n",
    "- Model is distributed, meaning all segment holders must consent in order to aggregate the model at the end of training.\n",
    "- The scalability of this approach, in terms of both network and computational resources, could make this an a valid alternative to FL and LBSGD, particularly on low power devices.\n",
    "- Could be an effective mechanism for both horizontal and vertical data distributions.\n",
    "- As computational cost is already quite low, proportianate homomorphic encryption cost is also minimised.\n",
    "- Only activation signal gradients are sent/ recieved, meaning that malicious actors cannot use gradients of model parameters to reverse engineer the original values\n",
    "\n",
    "### Constraints\n",
    "\n",
    "- A new technique with little surroundung literature, a large amount of compartison and evaluation is still to be done.\n",
    "- This approach requires all hosts to remain online during the entire learning process.\n",
    "    - makes approach less fesible for hand-held devices\n",
    "- Less established in toolkits than FL and LBSGD\n",
    "- While most aspects of the learning process are anonymised, the intermediary hosts are need to know the location of those ahead and behind to send and recieve data during learning. Ideally this would provide anonymity to participants.\n",
    "- This approach is less secure with small groups training but becomes more secure as the number of model segments increases\n",
    "\n",
    "### Tutorial \n",
    "\n",
    "The SpliNN has the capacity to be a significant contribution to the growing ecosystem of privacy preserving learning methodologies. This tutorial has three purposes;\n",
    "\n",
    "- To explain in as clear terms as possible what is going on during the training of a SplitNN.\n",
    "- To provide a working example of a SplitNN learning on arbitrary sets of; training data, model segments and data providers.\n",
    "- To provide an implementation of this technique on the PySyft framework so that this can be further validated against other techniques. \n",
    "\n",
    "Authors:\n",
    "- Adam Hall - Twitter: [@AJH4LL](https://twitter.com/AJH4LL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.1 - A Toy NN Example\n",
    "\n",
    "<img src=\"images/wholeNetwork.png\" width=\"60%\">\n",
    "\n",
    "\n",
    "We will begin by training a normal model to benchmark our SplitNN against. This will be the exact same specification as the SPlitNN onlt not distributed. In order to get as close as possible, we will use the same random seed for intitialisation. The dataset will take in arbitrary dataset of four binary features. The only x instance with a y value that is 1 will be 1111.\n",
    "\n",
    "<img src=\"images/benchmarkExample.png\" width=\"60%\">\n",
    "\n",
    "We will create three identical datasets to simulate the batches for each data owner.\n",
    "\n",
    "<img src=\"images/identicalDatasets.png\" width=\"40%\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "#from torchviz import make_dot, make_dot_from_trace\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "# A Toy Dataset\n",
    "data = torch.tensor([[0,0,0,0],[1,0,0,0],[0,1,0,0],[0,0,1,0],[1,1,0,0],[1,0,1,0],[0,1,1,0],[1,1,1,0],[0,0,0,1],[1,0,0,1],[0,1,0,1],[0,0,1,1],[1,1,0,1],[1,0,1,1],[0,1,1,1],[1,1,1,1.]])\n",
    "targets = torch.tensor([[0],[0],[0],[0],[0],[0],[0],[0],[1],[1],[1],[1],[1],[1],[1],[1.]])\n",
    "\n",
    "# Create 3 copies of the dataset\n",
    "datasets = [\n",
    "    (data.clone(), targets.clone())\n",
    "    for i in range(3)\n",
    "]\n",
    "\n",
    "# One Model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(4, 3),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(3, 3),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(3, 3),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(3, 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the parameter values for our model and the computation graph.\n",
    "\n",
    "<img src=\"images/wholeNetwork.png\" width=\"60%\">\n",
    "\n",
    "### Model Parameters and Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data)\n",
    "# make_dot(model(x), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Logic\n",
    "\n",
    "<img src=\"images/benchmarkExample.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y):\n",
    "    # Training logic\n",
    "    \n",
    "    epochs = 300\n",
    "    lr = 0.2\n",
    "    \n",
    "    opt = optim.SGD(params=model.parameters(),lr=lr)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # 1) erase previous gradients (if they exist)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # 2) make a prediction\n",
    "        pred = model(x)\n",
    "\n",
    "        # 3) calculate how much we missed\n",
    "        loss = ((pred - y)**2).sum()\n",
    "\n",
    "        # 4) figure out which weights caused us to miss\n",
    "        loss.backward()\n",
    "\n",
    "        # 5) change those weights\n",
    "        opt.step()\n",
    "\n",
    "        # 6) print our progress every 30 epochs\n",
    "        if epoch % 30 == 0:\n",
    "            print(f\"Epoch: {epoch}/{epochs} \\tLoss: \", \"{:.4f}\\tRuntime: {:.2f}s\".format(loss.data, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEXT BATCH\n",
      "Epoch: 0/300 \tLoss:  3.9986\tRuntime: 0.00s\n",
      "Epoch: 30/300 \tLoss:  3.9964\tRuntime: 0.02s\n",
      "Epoch: 60/300 \tLoss:  3.9931\tRuntime: 0.04s\n",
      "Epoch: 90/300 \tLoss:  3.9816\tRuntime: 0.06s\n",
      "Epoch: 120/300 \tLoss:  3.8692\tRuntime: 0.08s\n",
      "Epoch: 150/300 \tLoss:  0.0908\tRuntime: 0.10s\n",
      "Epoch: 180/300 \tLoss:  0.0213\tRuntime: 0.12s\n",
      "Epoch: 210/300 \tLoss:  0.0115\tRuntime: 0.14s\n",
      "Epoch: 240/300 \tLoss:  0.0078\tRuntime: 0.16s\n",
      "Epoch: 270/300 \tLoss:  0.0058\tRuntime: 0.18s\n",
      "\n",
      "NEXT BATCH\n",
      "Epoch: 0/300 \tLoss:  0.0046\tRuntime: 0.00s\n",
      "Epoch: 30/300 \tLoss:  0.0039\tRuntime: 0.02s\n",
      "Epoch: 60/300 \tLoss:  0.0033\tRuntime: 0.05s\n",
      "Epoch: 90/300 \tLoss:  0.0029\tRuntime: 0.07s\n",
      "Epoch: 120/300 \tLoss:  0.0025\tRuntime: 0.09s\n",
      "Epoch: 150/300 \tLoss:  0.0023\tRuntime: 0.11s\n",
      "Epoch: 180/300 \tLoss:  0.0021\tRuntime: 0.13s\n",
      "Epoch: 210/300 \tLoss:  0.0019\tRuntime: 0.15s\n",
      "Epoch: 240/300 \tLoss:  0.0017\tRuntime: 0.17s\n",
      "Epoch: 270/300 \tLoss:  0.0016\tRuntime: 0.19s\n",
      "\n",
      "NEXT BATCH\n",
      "Epoch: 0/300 \tLoss:  0.0015\tRuntime: 0.00s\n",
      "Epoch: 30/300 \tLoss:  0.0014\tRuntime: 0.02s\n",
      "Epoch: 60/300 \tLoss:  0.0013\tRuntime: 0.04s\n",
      "Epoch: 90/300 \tLoss:  0.0012\tRuntime: 0.07s\n",
      "Epoch: 120/300 \tLoss:  0.0012\tRuntime: 0.09s\n",
      "Epoch: 150/300 \tLoss:  0.0011\tRuntime: 0.11s\n",
      "Epoch: 180/300 \tLoss:  0.0011\tRuntime: 0.13s\n",
      "Epoch: 210/300 \tLoss:  0.0010\tRuntime: 0.15s\n",
      "Epoch: 240/300 \tLoss:  0.0010\tRuntime: 0.18s\n",
      "Epoch: 270/300 \tLoss:  0.0009\tRuntime: 0.20s\n",
      "\n",
      "Final Predictions:\n",
      " tensor([[0.0084, 0.0075, 0.0077, 0.0074, 0.0070, 0.0069, 0.0071, 0.0066, 0.9930,\n",
      "         0.9926, 0.9928, 0.9927, 0.9925, 0.9922, 0.9924, 0.9919]])\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(\"\\nNEXT BATCH\")\n",
    "    data, targets = dataset\n",
    "    train(data, targets)\n",
    "\n",
    "print(\"\\nFinal Predictions:\\n\", torch.t(model(data)).data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.1 - A Distributed Training Example\n",
    "\n",
    "We will train a splitNN model that has been distributed to three different hosts. One host, Alice, is the data subject. Alice has the labelled data and will also be the custodian of the network start and end segments. Claire and Bob are worker hosts. They will feed the activation signals from the start of the chain forward until it reaches alices end layer. They will do the reverse with gradients in the backpropogation process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1.1 - Set up environmental variables\n",
    "\n",
    "Here we will import our required libraries and initialise our model segments and data. We will need;\n",
    "\n",
    "<img src=\"images/distributed.png\" width=\"50%\">\n",
    "\n",
    "- A dummy distributed dataset\n",
    "- 5 model segments\n",
    "- 3 Virtual Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "#from torchviz import make_dot, make_dot_from_trace\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def location(self):\n",
    "    m = self.__getitem__(0)\n",
    "    w = m.weight[0]\n",
    "    return w.location\n",
    "\n",
    "nn.Sequential.location = location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Toy Dataset\n",
    "x = torch.tensor([[0,0,0,0],[1,0,0,0],[0,1,0,0],[0,0,1,0],[1,1,0,0],[1,0,1,0],[0,1,1,0],[1,1,1,0],[0,0,0,1],[1,0,0,1],[0,1,0,1],[0,0,1,1],[1,1,0,1],[1,0,1,1],[0,1,1,1],[1,1,1,1.]])\n",
    "y = torch.tensor([[0],[0],[0],[0],[0],[0],[0],[0],[1],[1],[1],[1],[1],[1],[1],[1.]])\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Define 5 chained models\n",
    "models = [\n",
    "    nn.Sequential(\n",
    "        nn.Linear(4, 3),\n",
    "        nn.Tanh()\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(3, 3),\n",
    "        nn.Sigmoid()\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(3, 3),\n",
    "        nn.Sigmoid()\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(3, 2),\n",
    "        nn.Tanh()\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(2, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "]\n",
    "\n",
    "# create some workers\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "claire = sy.VirtualWorker(hook, id=\"claire\")\n",
    "workers = alice, bob, claire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final predictions are shown above, we can compare this with the output of the same 'split' neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1.2 - Send Variables to Starting Locations\n",
    "\n",
    "In this example, Alice is the worker with the data and labels. Bob and Claire are intermediary hosts in the chain. Alice has the start and end model segments. Bob and Claire have intermediary segments.\n",
    "\n",
    "We send the models and data to their respective hosts and store the pointers in associative arrays; the Model Chain (MC) and the xy Chain (xyC). These contain the locations of the data, but no actual values. These are the only necessary parameters for coordinating this learning process. A summary of this is seen below\n",
    "\n",
    "<img src=\"images/Parameters.png\" width=\"50%\">\n",
    "\n",
    "In this experiment, the models and data are initialised locally and then distributed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Send Model Segments to starting locations\n",
    "model_locations = [alice, alice, bob, claire, alice]\n",
    "\n",
    "for model, location in zip(models, model_locations):\n",
    "    model.send(location)\n",
    "\n",
    "\n",
    "# Create a remote copy of the dataset for each worker\n",
    "datasets = [\n",
    "    sy.BaseDataset(x.send(worker), y.send(worker))\n",
    "    for worker in (alice, bob, claire)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1.3 - Forward Propogation\n",
    "\n",
    "We will need to define the logic of forward and backward propogation. \n",
    "\n",
    "Forward propogation feeds the input data into Alice's segment at the beginning of the chain. Alice then sends her activation signal to the location of the next model in the chain. This model propogates this activation and sends it onward to the location of the next segment. The signal will eventually reach alice's end segment to perform a prediction. We store pointers to the activations of each layer using the Activation Chain (AC). This allows us to retrieve the values when processing gradients. When the activations have fully propogated the MC, the method returns the resultant AC for use in the backpropogation function. \n",
    "\n",
    "<img src=\"images/activationchain.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(models, x):\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    # First: provide x as input\n",
    "    inputs.append(x)\n",
    "    outputs.append(models[0](x))\n",
    "    next_input = outputs[-1].copy().get().send(models[1].location)\n",
    "    \n",
    "    for i in range(1, len(models)-1):\n",
    "        inputs.append(next_input)\n",
    "        outputs.append(models[i](next_input))\n",
    "        next_input = outputs[-1].copy().get().send(models[i+1].location)\n",
    " \n",
    "    # Last: don't move the result to the next location\n",
    "    inputs.append(next_input)\n",
    "    outputs.append(models[len(models)-1](next_input))\n",
    "    \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1.4 - Backward Propogation\n",
    "\n",
    "The backpropogation function takes the MC, xyC and AC as input parameters.\n",
    "\n",
    "<img src=\"images/backpropParams.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "First the backpropogation algorithm computes the loss on Alice's prediction. We use <b>**** what seems to be**** </b> the sum of squared error as our loss function.\n",
    "\n",
    "<img src=\"images/loss.png\" width=\"100%\">\n",
    "\n",
    "We then calculate the gradients for the parameters of the end segment using the chain rule.\n",
    "\n",
    "<img src=\"images/chainRule.png\" width=\"40%\">\n",
    "\n",
    "This is done automatically for the layers in each segment but we have to recalculate loss for each model segment during the backpropogation phase.\n",
    "\n",
    "<img src=\"images/intermediateLoss.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Each segment feeds the gradients of their activation function back to the segment behind them and updates their weights w.r.t these gradients. This layer computes it's loss by dot joining the orignal activation signal and it's new gradient. The sum of the result is used to feed back error down the line. After each segment is complete, the optimiser for that model updates. The process is repeated until the segment at the beginning of the chain is reached and alice updates the gradients on her beginning segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(models, optimizers, segment_inputs, segment_outputs, dataset):\n",
    "    data, targets = dataset.data, dataset.targets\n",
    "        \n",
    "    # Destroy pre-existing gradient of final layer\n",
    "    optimizers[len(optimizers)-1].zero_grad()\n",
    "   \n",
    "    #     TODO: LOOKS LIKE JUST SQUARED ERROR, NOT MEAN SQUARED. \n",
    "    #         NOT SURE IF I HAVE THE RIGHT LOSS EQUATION. COULD BE\n",
    "    #         THAT THIS IS DONE AS PART OF THE .SUM() FUNCTION THOUGH?\n",
    "    #         WHEN I ADD THE /n PART IT DOESN'T LEARN SO WELL..\n",
    "    # Calculates Loss\n",
    "    loss = (((segment_outputs[-1] - targets)**2).sum())\n",
    "\n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # End layer sends the gradient of the activation signal back to the layer behind\n",
    "    input_gradient = segment_inputs[-1].grad.clone().get().send(models[len(models)-2].location)\n",
    "    \n",
    "    # End layer updates weights\n",
    "    optimizers[-1].step()\n",
    "\n",
    "    # Compute Intermediary Layers: repeat the same operations\n",
    "    for iter in range(len(models)-1, 1, -1): \n",
    "        optimizers[iter-1].zero_grad()\n",
    "        intermediate_loss = torch.matmul(torch.t(segment_outputs[iter-1]), input_gradient).sum()\n",
    "        intermediate_loss.backward()\n",
    "        input_gradient = segment_inputs[iter-1].grad.clone().get().send(models[iter-2].location)\n",
    "        optimizers[iter-1].step()\n",
    "\n",
    "    # Compute Final Layer, same but now input is the real input data\n",
    "    optimizers[0].zero_grad()\n",
    "    segment_output = segment_outputs[0]\n",
    "    intermediate_loss = torch.matmul(torch.t(segment_output), input_gradient).sum()\n",
    "    intermediate_loss.backward()\n",
    "    optimizers[0].step()\n",
    "        \n",
    "    return segment_outputs[-1], loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1.5 - Run Training Logic\n",
    "\n",
    "Now we will run the training process over 200 epochs for each data owner. Every 20 epochs we will print our progress. The front and end sections of the model will be swapped between data owners training each individual batch.\n",
    "\n",
    "<img src=\"images/BatchFlow.png\" width=\"40%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitNN_train(models, xyChain):\n",
    "    \n",
    "    #   Variables for performance metrics\n",
    "    start_time = time.time()\n",
    "    epochs = 300\n",
    "    lr = 0.2\n",
    "    counter = 0\n",
    "    \n",
    "    # Create optimisers for each segment and link to their segment\n",
    "    optimizers = [\n",
    "        optim.SGD(params=model.parameters(),lr=lr)\n",
    "        for model in models\n",
    "    ]\n",
    "    \n",
    "    for i, local_worker in enumerate(workers):\n",
    "        \n",
    "        # Begin work on current data subject\n",
    "        dataset = datasets[i]\n",
    "        \n",
    "        print('*', dataset.location.id, models[0].location.id)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Forward propogate through network until final layer is reached\n",
    "            segment_inputs, segment_outputs = forward(models, dataset.data)\n",
    "            \n",
    "            # Backward propogate\n",
    "            predictions, loss = backward(models, optimizers, segment_inputs, segment_outputs, dataset)\n",
    "\n",
    "            if epoch % 30 == 0:\n",
    "                print(f\"Epoch: {epoch}/{epochs} \\tLoss: \", \"{:.4f}\\tRuntime: {:.2f}s\".format(loss.get().data, time.time() - start_time))\n",
    "        \n",
    "        # If we are not at the end of the data owner chain send perimeter segments to next data owner\n",
    "        if i < len(workers)-1:\n",
    "            models[0].get().send(datasets[i+1].location)\n",
    "            models[len(models)-1].get().send(datasets[i+1].location)      \n",
    "            \n",
    "\n",
    "            print(\"\\nNEXT DATA OWNER\\n\")\n",
    "            print(\"MODEL CHAIN LOCATIONS\")\n",
    "            for iter in range(len(models)):\n",
    "                print(models[iter].location.id)  \n",
    "            print(\"\\n\")\n",
    "    \n",
    "    # Send models back to researcher\n",
    "    [model.get() for model in models]\n",
    "    \n",
    "    # Perform predictions with updates weights\n",
    "    out = torch.tensor([[0,0,0,0],[1,0,0,0],[0,1,0,0],[0,0,1,0],[1,1,0,0],[1,0,1,0],[0,1,1,0],[1,1,1,0],[0,0,0,1],[1,0,0,1],[0,1,0,1],[0,0,1,1],[1,1,0,1],[1,0,1,1],[0,1,1,1],[1,1,1,1.]])\n",
    "    for i in range(len(models)):\n",
    "        out = models[i](out)\n",
    "        \n",
    "    print(\"\\n\\nFinal Predictions:\", torch.t(out).data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* alice alice\n",
      "Epoch: 0/300 \tLoss:  3.9986\tRuntime: 0.02s\n",
      "Epoch: 30/300 \tLoss:  3.9976\tRuntime: 0.70s\n",
      "Epoch: 60/300 \tLoss:  3.9973\tRuntime: 1.39s\n",
      "Epoch: 90/300 \tLoss:  3.9970\tRuntime: 2.05s\n",
      "Epoch: 120/300 \tLoss:  3.9966\tRuntime: 2.74s\n",
      "Epoch: 150/300 \tLoss:  3.9963\tRuntime: 3.42s\n",
      "Epoch: 180/300 \tLoss:  3.9959\tRuntime: 4.12s\n",
      "Epoch: 210/300 \tLoss:  3.9955\tRuntime: 4.88s\n",
      "Epoch: 240/300 \tLoss:  3.9951\tRuntime: 5.70s\n",
      "Epoch: 270/300 \tLoss:  3.9946\tRuntime: 6.52s\n",
      "\n",
      "NEXT DATA OWNER\n",
      "\n",
      "MODEL CHAIN LOCATIONS\n",
      "bob\n",
      "alice\n",
      "bob\n",
      "claire\n",
      "bob\n",
      "\n",
      "\n",
      "* bob bob\n",
      "Epoch: 0/300 \tLoss:  3.9940\tRuntime: 7.36s\n",
      "Epoch: 30/300 \tLoss:  3.9934\tRuntime: 8.15s\n",
      "Epoch: 60/300 \tLoss:  3.9926\tRuntime: 8.97s\n",
      "Epoch: 90/300 \tLoss:  3.9917\tRuntime: 9.80s\n",
      "Epoch: 120/300 \tLoss:  3.9905\tRuntime: 10.70s\n",
      "Epoch: 150/300 \tLoss:  3.9889\tRuntime: 11.52s\n",
      "Epoch: 180/300 \tLoss:  3.9868\tRuntime: 12.31s\n",
      "Epoch: 210/300 \tLoss:  3.9836\tRuntime: 13.11s\n",
      "Epoch: 240/300 \tLoss:  3.9774\tRuntime: 13.91s\n",
      "Epoch: 270/300 \tLoss:  3.9534\tRuntime: 14.70s\n",
      "\n",
      "NEXT DATA OWNER\n",
      "\n",
      "MODEL CHAIN LOCATIONS\n",
      "claire\n",
      "alice\n",
      "bob\n",
      "claire\n",
      "claire\n",
      "\n",
      "\n",
      "* claire claire\n",
      "Epoch: 0/300 \tLoss:  0.1933\tRuntime: 15.47s\n",
      "Epoch: 30/300 \tLoss:  0.0219\tRuntime: 16.22s\n",
      "Epoch: 60/300 \tLoss:  0.0111\tRuntime: 17.00s\n",
      "Epoch: 90/300 \tLoss:  0.0074\tRuntime: 17.76s\n",
      "Epoch: 120/300 \tLoss:  0.0055\tRuntime: 18.52s\n",
      "Epoch: 150/300 \tLoss:  0.0044\tRuntime: 19.29s\n",
      "Epoch: 180/300 \tLoss:  0.0037\tRuntime: 20.08s\n",
      "Epoch: 210/300 \tLoss:  0.0031\tRuntime: 20.86s\n",
      "Epoch: 240/300 \tLoss:  0.0027\tRuntime: 21.64s\n",
      "Epoch: 270/300 \tLoss:  0.0024\tRuntime: 22.41s\n",
      "\n",
      "\n",
      "Final Predictions: tensor([[0.0117, 0.0116, 0.0116, 0.0116, 0.0116, 0.0116, 0.0116, 0.0116, 0.9883,\n",
      "         0.9883, 0.9883, 0.9883, 0.9883, 0.9883, 0.9883, 0.9883]])\n"
     ]
    }
   ],
   "source": [
    "splitNN_train(models, datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "- The SplitNN trains more slowly than the centralised network.\n",
    "    - This is expected due to the current processing redundancies and network latencies ().\n",
    "- The SplitNN takes more epochs to train correctly\n",
    "    - This could be to do with the way that loss is transferred down the line (the activation signals and corresponding gradients are dot-joined and summed. This acts as a loss equation for computing the gradients of intermediate layers)\n",
    "    - The same random seed is used when generating both models in order to make these as similar as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work\n",
    "\n",
    "- The present approach stops anyone from having knowledge of the NN segment behind them. This is true except in one instance. When Alice passes segment 1 and 5 to Bob, Alice has prior knowledge of Segment 1. Then when Bob then passes his x values through and sends the resultant a values to segment 2 (Alice), Alice knows the model and resultant activation signal. Alice also knows the error being fed back so she can maintain knowledge of the model as it's. With the knowledge of the model and activation signals, Alice could reverse engineer Bob's x values.\n",
    "    - This could potentially be solved by homomorphically encrypting x values being fed into the model. Alice would then not know the activation signal, however a robust approach for this is yet to be established.\n",
    "- A tokenisation infrastructure or masked dns service could be implemented to provide anonymity to hosts during traing. Ideally the difference 'chains' involved here could be written to a smart contract and be publicly available information. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- Figure out whether we need to reconstruct computation graph at each layer\n",
    "    - I am unclear as to whether i can work with a computation graph that is distributed. For this reason I recreate the computation graph by pushing through the activation signals of An-1 again and recompute error with that. This means that we are doing around twice the computation, which is a bad thing. Hopefully there is a workaround!\n",
    "- Implement .move() instead of .get().send()\n",
    "    - Should move data directly between owners"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
